\documentclass[article]{jss}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage{Sweave}    
%\usepackage{Rd}    


%%% INFOS FOR YUIMA CORE TEAM %%%

% USE THIS IF YOU DON'T WANT TO EXECUTE R CODE
\SweaveOpts{prefix.string=yuima, echo=TRUE, eval=FALSE}

% USE THIS INSTEAD IF YOU WANT TO EXECUTE R CODE
\SweaveOpts{prefix.string=yuima, echo=TRUE, eval=TRUE}

%% before editing this file get the new version, type this command on Terminal
%% in the same directory where this Rnw-file lives
%% svn up

%% HOW TO BUILD THIS FILE
%% from inside the directory where this Rnw-file lives
%% ./script.sh article-new

%% to commit to svn the changes type
%% from inside the directory where this Rnw-file lives
%% svn commit -m "my changes"

\usepackage{amsmath,amssymb}

\usepackage[utf8x]{inputenc} 

\usepackage{comment}
\excludecomment{en-text}

\usepackage{enumerate}%\begin{enumerate}[{(}i{)}]
\usepackage{bm}
\usepackage{bbm} %\mathbbm{ABCabc\nabla}
\usepackage[bbgreekl]{mathbbol} %\mathbb{abcABC\nabla\bbalpha\bbbeta\Delta  }
\usepackage{natbib}
\usepackage{dsfont}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{latexsym}
\usepackage{amsmath}

\def\be{\begin{equation}}
\def\ee{\end{equation}}
\def\bea{\begin{eqnarray}}
\def\eea{\end{eqnarray}}
\def\beas{\begin{eqnarray*}}
\def\eeas{\end{eqnarray*}}
\def\sskip{\hspace{5mm}}

\newcommand{\colorr}{\color[rgb]{0.8,0,0}}
\newcommand{\colorg}{\color[rgb]{0,0.5,0}}
\newcommand{\colorb}{\color[rgb]{0,0,0.8}}
\newcommand{\colord}{\color[rgb]{0.8,0.3,0}}
\newcommand{\colorn}{\color[rgb]{1,1,1}}
\newcommand{\colorred}{\color[rgb]{0.8,0,0}}
\newcommand{\colory}{\color{yellow}}
\newcommand{\coloro}{\color[rgb]{1,0.4,0}}%{1,0.851,0}}
\newcommand{\coloroy}{\color[rgb]{1,0.95,0}}
\newcommand{\colorsb}{\color[rgb]{0,0.95,1}}
\newcommand{\colorro}{\color[rgb]{0.851,0.255,0.467}} %rose


%% almost as usual
\author{Alexandre Brouste\\University of Le Mans \And 
        Masaaki Fukasawa\\Osaka University\And
        Hideitsu Hino\\Waseda University\And
        Stefano M. Iacus\\University of Milan \AND 	
        Kengo Kamatani\\University of Tokyo \And
        Yuta Koike\\University of Tokyo\And
        Hiroki Masuda\\Kyushu University \And
        Ryosuke Nomura\\University of Tokyo\AND
        Teppei Ogihara\\Osaka University \And
        Yasutaka Shimuzu\\Osaka University \And
        Masayuki Uchida\\Osaka University \And
        Nakahiro Yoshida\\University of Tokyo 
        }
\title{The YUIMA Project: a Computational Framework for Simulation and Inference of Stochastic Differential Equations}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Alexandre Brouste, Stefano M. Iacus, Hiroki Masuda, Masayuki Uchida, Nakahiro Yoshida} %% comma-separated
\Plaintitle{YUIMA: Simulation and Inference for SDE} %% without formatting
\Shorttitle{The YUIMA Project} %% a short title (if necessary)

%% an abstract and keywords
\Abstract{
The Yuima Project is an open source and collaborative effort  aimed at developing the \proglang{R} package named \pkg{yuima} for simulation and inference of stochastic differential equations. 

In the \pkg{yuima} package stochastic differential equations can be of very abstract type, multidimensional, driven by Wiener process or fractional Brownian motion with general Hurst parameter, with or without jumps specified as L\'evy noise. 

The \pkg{yuima} package is intended to offer the basic infrastructure on which complex models and inference procedures can be built on. This paper explains the design of the \pkg{yuima} package and provides some examples of applications.
}
\Keywords{inference for stochastic processes, simulation, stochastic differential equations}
\Plainkeywords{inference for stochastic processes, simulation, stochastic differential equations} %% without formatting
%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{13}
%% \Issue{9}
%% \Month{September}
%% \Year{2004}
%% \Submitdate{2004-09-29}
%% \Acceptdate{2004-09-29}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
  Stefano M. Iacus\\
  Department of Economics, Management and Quantitative Methods\\
  University of Milan\\
  Via Conservatorio 7, 20122 Milan, Italy\\
  E-mail: \email{stefano.iacus@unimi.it}\\
  URL: \url{http://www.economia.unimi.it/~iacus/}
\\
\\
  Nakahiro Yoshida\\
  Graduate School of Mathematical Science\\
  University of Tokyo\\
  3-8-1 Komaba, Meguro-ku,  Tokyo 153-8914, Japan\\
  E-mail: \email{nakahiro@ms.u-tokyo.ac.jp}\\
  URL: \url{http://www.ms.u-tokyo.ac.jp/~nakahiro/hp-naka-e}
}
%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: +43/1/31336-5053
%% Fax: +43/1/31336-734


%% preamble for Rnw files
<<print=FALSE, echo=FALSE>>=
options(prompt="R> ")
options(width=60)
@

\def\ep{{\varepsilon}}
\def\ve{{\varepsilon}}
\def\de{{\rm d}}
\def\dE{{\mathbb E}}
\def\diag{\mathop{\rm diag}\nolimits}

%% for those who use Sweave please include the following line (with % symbols):
%% need no \usepackage{Sweave.sty}
%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}




%% include your article here, just as usual
%% Note that you should use the \pkg{}, \proglang{} and \code{} commands.

%\section[About Java]{About \proglang{Java}}
%% Note: If there is markup in \(sub)section, then it has to be escape as above.








\section{Introduction}
The plan of the YUIMA Project is to construct the bases for a complete environment for simulation and inference for stochastic processes via an \proglang{R} \citep{ERRE} package called \pkg{yuima}.
% The package \pkg{yuima} provides an object-oriented programming environment for simulation and statistical inference for stochastic processes by \proglang{R}.
The \pkg{yuima} package adopts the  S4 system of classes and methods \citep{chambers98}.
 
Under this framework, 
the \pkg{yuima} package also supplies various functions 
to carry out simulation and statistical analysis. 
Both categories of procedures may depend on each other.
Statistical inference often requires a simulation technique 
as a subroutine, and a certain simulation method 
needs to fix a tuning parameter by applying 
a statistical methodology. 
It is especially the case of stochastic processes 
because most of expected values involved 
do not admit an explicit expression. 
The \pkg{yuima} package facilitates comprehensive, systematic approaches 
to the solution. 


Stochastic differential equations are 
commonly used 
to model random evolution along continuous or 
practically continuous time, such as 
the random movements of stock prices. 
Theory of statistical inference for 
stochastic differential equations already has a fairly long history, 
more than three decades, but it is still developing quickly new 
methodologies and expanding the area. 
The formulas produced by the theory are usually very sophisticated, 
which makes it difficult for standard users not necessarily 
familiar with this field to enjoy utilities. 
For example, by taking advantage of the analytic approach,  the asymptotic expansion method for computing 
option prices (i.e., expectation of an irregular functional of 
a stochastic process) provides precise approximation values 
instantaneously. The expansion formula, which has a long expression involving more than 900 terms of multiple integrals, is already coded in the \pkg{yuima} package for generic diffusion processes.


The \pkg{yuima} package delivers up-to-date methods as a package 
onto the desk of the user working 
with simulation and/or statistics for stochastic differential equations. 
In the \pkg{yuima} package, stochastic differential equations can be of very abstract type, 
multidimensional, driven by Wiener process or fractional Brownian motion 
with general Hurst parameter, with or without jumps specified as L\'evy noise. 



The \pkg{yuima} package is intended to offer the basic infrastructure on which complex models and inference procedures can be built on. This paper explains the design of the \pkg{yuima} package and illustrates some examples of applications.
The paper is organized as follows. Section \ref{sec2} is an overview about the package. Section \ref{sec3} describes the way in which models are specified in \pkg{yuima}. Section \ref{sec4} explains asymptotic expansion methods. Section \ref{sec5} is a review of basic inference procedures. 
Finally, Section \ref{sec6} gives additional details and the roadmap of the YUIMA Project.


Although we assume that the reader of this paper has a basic knowledge of the \proglang{R} language, most of the examples are easy to understand 
if he/she knows stochastic differential equations intuitively or symbolically. 


\section{The \pkg{yuima} Package}\label{sec2}
The package \pkg{yuima} depends on some other packages, like  \pkg{zoo} \citep{zoo}, which can be installed separately.
The package \pkg{zoo} is used internally to store time series data. This dependence may change in the future adopting a more flexible class for internal storage of time series.

\subsection{How to Obtain the Package}
The \pkg{yuima} package is hosted on R-Forge and the web page
of the Project is  \url{http://r-forge.r-project.org/projects/yuima}.
The  R-Forge page contains the latest development version, and stable
version of the package will also be available through CRAN.
Development versions of the package are not supposed to be stable or functional, thus
the occasional user should consider to install the stable version first.
The package can be installed from R-Forge using
\code{install.packages("yuima",repos="http://R-Forge.R-project.org")}.
If, the R-Forge system does not provide binary builds of the \pkg{yuima} package, the
user can also try 
\code{install.packages("yuima",repos="http://R-Forge.R-project.org", type="source")}.


\subsection{The Main Object and Classes}
Before discussing the methods for simulation and inference for stochastic processes solutions to stochastic differential equations, here we discuss the main classes in the package.
As mentioned there are different classes of objects defined in the \pkg{yuima} package and
the main class is called the \code{yuima-class}. This class  is composed of several slots.
Figure \ref{fig:classes} represents the different classes and their slots.
\begin{figure}[th]
\centering{\includegraphics[width=\textwidth]{yuima-class}}
\caption{The main classes in the \pkg{yuima} package.}
\label{fig:classes}
\end{figure} 
The different slots do not need to be all present at the same time. For example, in case one wants to simulate a stochastic process, only the slots \code{model} and \code{sampling} should be present, while the slot \code{data} will be filled by the simulator.
We discuss in details the different objects separately in the next sections.

The general idea of the \pkg{yuima} package is to separate into different subclass objects the statistical model, the data and the statistical methods. As will be explained with several examples, the user may give a mathematical description of the statistical model with \code{setModel} which prepares a \code{yuima.model} object by filling the appropriate slots. If the aim is the simulation of the solution of the stochastic  differential equation specified in the \code{yuima.model} object then, using the method \code{simulate}, it is possible to obtain one trajectory of the process. As an output, a \code{yuima} object is created which contains the original model specified in the \code{yuima.model} object in the slot named \code{model} and two additional slots named \code{data}, for the simulated data, and \code{sampling} which contains the description of the simulation scheme used as well as other informations. The details of \code{simulate} will be explained in Section \ref{sec:simul} along with the use of method \code{setSampling} which allows to specify the type of sampling scheme to be used by the \code{simulate} method.
But \code{yuima} object may contain the slot \code{data} non only as the outcome of \code{simulate} but also because the user decides to analyse its own data. In this case the method \code{setData} is used to transform most types  of \proglang{R} time series object into a a proper \code{yuima.data} object.
When the slots \code{data} and \code{model} are available, many other methods can be used to perform statistical analysis on these sde's models. These methods will be discussed in Section \ref{sec5}.
Further, functionals of stochastic differential equations can be defined using the \code{setFunctional} method and evaluated using asymptotc expansion methods as explained in Section \ref{sec4}. The \code{setFunctional} method creates a \code{yuima.functional} object which is included along with a \code{yuima.model}  into a \code{yuima} object in order to be used for the evaluation of its asymptotic expansion.


\subsection{The \code{yuima.model} Class}\label{sec:model}
At present, in \pkg{yuima}  three main classes of stochastic differential equations  can be easily specified.  Here we present  a brief
overview of these models as they will be described in details in Section \ref{sec3}, but this allow to introduce an overall view of the slots of the \code{yuima.model} class.
In \pkg{yuima} one can describe three main families of stochastic processes at present. These models can be one or multidimensional and eventually described as parametric models. Let $X_0=x_0$ be the initial value of the process, then, the main classes are as follows:
\begin{itemize}
\item diffusion models described as
$$  \de X_t=a(t,X_t,\theta)dt + b(t,X_t,\theta)\de W_t, \quad X_0=x_0$$
 where $W_t$ is a standard Brownian motion;
\item sde's driven by fractional Gaussian noise, with $H$ the Hurst parameter, described as
$$ \de X_t=a(t,X_t,\theta)dt + b(t,X_t,\theta)\de W_t^{H}, \quad X_0=x_0;$$ 
\item diffusion process with jumps and  L\'evy processes solution to
$$
\begin{aligned}
\de X_t = & \,\,\, a(t,X_t,\theta)\de t + b(t,X_t,\theta)\de W_t + \int\limits_{|z|>1}\!\!\! c(X_{t-},z)\mu(\de t,\de z) \\
&{}+\!\! \int\limits_{0<|z|\le 1}\!\!\!  c(X_{t-},z)\{\mu(\de t,\de z) - \nu(\de z)\de t\}
\end{aligned}, \quad X_0=x_0;
$$
\end{itemize}
 The functions $a(\cdot)$, $b(\cdot)$ and $c(\cdot)$ may have a different number of arguments. For example, if the model is homogeneous in time and drift and diffusion coefficients are entirely specified, then we will use the notaion $a(x)$ and $b(x)$ and describe the diffusion model simply as $\displaystyle \de X_t=a(X_t)dt + b(X_t)\de W_t$. And so forth. Detailed hypotheses and regularity conditions on the coefficients $a(\cdot)$, $b(\cdot)$ and $c(\cdot)$ for each class of models will be given in the next sections. Nevertheless, it is important to remark that these notations only matter the mathematical description of the model while each coefficient is passed to \pkg{yuima} methods as \proglang{R} mathematical expressions. It means that, for example, $a(t, X_t, \theta) = t\cdot \sqrt{\theta X_t}$ will be passed as \code{t*sqrt(x*theta)}, therefore, the order of the arguments is not relevant to \proglang{R} as well as its mathematical description as long as it is consistent through each specific section. Furhter, \pkg{yuima} is able to accept any user-specified notation for the state variable $x$ (for $X_t$) and the time variable $t$ and the remaining term of an \proglang{R} expression will be interpreted as parameter as will explained in Section \ref{sec:diff}.
We are now able to give an overview of the mian slots of the most important class of the \pkg{yuima} package.

The \code{yuima.model} class contains information about the stochastic differential equation of interest. The constructor function \code{setModel} is
used to give a mathematical description of the stochastic differential equation. 
All functions in the package are assumed to get as much information
as possible from the model instead of replicating the same code everywhere.
If there are missing pieces of information, we may change or extend the description
of the model.
\\
\\
An object of class \code{yuima.model} contains several slots listed below. 
To see inside its structure, one can use the \proglang{R} command \code{str} on a \pkg{yuima} object.
\begin{itemize}
\item \code{drift} is an \proglang{R} vector of expressions which contains the drift specification;
\item \code{diffusion} is itself a list of 1 slot which describes the diffusion
  coefficient matrix relative to first noise;
\item \code{hurst} is the Hurst index of the fractional Brownian motion, by default \code{0.5}  meaning a standard Brownian motion. More details will be given in Section \ref{sec:fgn};
\item \code{parameter},  which is a short name for ``parameters'',  
  is a list with the following entries (explained details in Section \ref{sec:par}):
\begin{itemize}
\item \code{all} contains the names of all the parameters found 
   in the diffusion and drift coefficient;
\item \code{common} contains the names of the parameters in common between the drift and diffusion coefficients;
\item \code{diffusion} contains the parameters belonging to the diffusion coefficient;
\item \code{drift} contains the parameters belonging to the drift coefficient;
\item \code{jump} contains the parameters belonging to the  coefficient of the L\'evy noise;
\item \code{measure} contains the parameters describing the L\'evy measure (explained details in Section \ref{sec:jump});
\end{itemize}
\item \code{measure} specifies the measure of the L\'evy noise (see Section \ref{sec:jump});
\item \code{measure.type} a switch to specify how the L\'evy measure is described (see Section \ref{sec:jump});
\item \code{state.variable} and \code{time.variable}, by default,
  are assumed to be \code{x} and \code{t} but the user can freely choose them and they matter the right hand-side of the equation of the sde.
  The \code{yuima.model} class assumes that the user either uses default
  names for \code{state.variable} and \code{time.variable} variables or specify his own names. All
  the rest of the symbols are considered parameters and distributed accordingly
  in the \code{parameter} slot. Example of use will be given in Section \ref{sec:diff};
\item \code{jump.variable} the name of the variable used in the description of the L\'evy component (see Section \ref{sec:jump});
\item \code{solve.variable} contains a vector of variable names, each element corresponds to the
   name of the solution variable (left-hand-side) of each equation in the model, in the corresponding order. An example of use can be found in Section \ref{sec:multi}.
\item \code{noise.number} indicates the number of sources of noise.
\item \code{xinit} initial value of the stochastic differential equation;
\item \code{equation.number} represents the number of equations, i.e., the number of one dimensional
  stochastic differential equations.
\item \code{dimension} reports the dimensions of the parameter space. It is a list of the
  same length of \code{parameter} with the same names.
\item \code{J.flag} for internal use only.
\end{itemize}
As seen in the above, the parameter space is accurately described internally in a \code{yuima} object because in inference for stochastic differential equations, estimators of different parameters have different properties. Usually, the rate of convergence for estimators in the diffusion coefficient are similar to the ones in the i.i.d. sampling while estimators of parameters in the drift coefficient are slower or, in some cases, not even consistent. The \pkg{yuima} always tries to implement the best statistical inference for the given model under the observed sampling scheme.

\section{Model Specification}\label{sec3}
In order to show how general the approach is in the \pkg{yuima} package we present some examples. Throughout this section we assume that all the stochastic differential equations exists while in Section \ref{sec5} we will give precise regularity conditions needed to have a properly defined statistical model.

\subsection{One Dimensional Diffusion Processes}\label{sec:diff}
Assume that we want to describe the following stochastic differential equation
$$\de X_t = -3 X_t \de t + \frac{1}{1+X_t^2}\de W_t.$$
In the above $a(x) = -3 x$ and $b(x) = \frac{1}{1+x^2}$ according to the notaion of previous section and $W_t$ is a standard Wiener process.
This can be described in \pkg{yuima} by specifying the drift and diffusion coefficients as plain
\proglang{R} expressions passed as strings
<<print=FALSE,echo=FALSE,results=hide>>=
library(yuima)
@ 
<<echo=TRUE, print=FALSE,results=hide>>=
mod1 <- setModel(drift = "-3*x", diffusion = "1/(1+x^2)")
@ 
By default, \pkg{yuima} assumes that the state variable is \code{x} and the time variable is \code{t} and the solve variable is again \code{x}. Notice that the left hand-side of the equation is implicit, this is why \code{yuima.model} has the slot \code{solve.variable.
The user should not we worried about the warning raised by \pkg{yuima} at this stage, as this is just to inform the user about the implicit assumption on the solution variable.}
At this point, the package fills the proper slots of the \code{yuima} object
<<>>=
str(mod1)
@

From the above, it is possible to see that the jump coefficient is void and the Hurst parameter is set to 0.5, because this is a model where the driving process is the standard Brownian motion, i.e. a fractional Brownian motion if Hurst index $H=\frac12$.
Now, with \code{mod1} in hands, it is very easy to simulate a trajectory by  Euler-Maruyama scheme of the process as follows
<<echo=TRUE, print=FALSE,fig=TRUE,width=9,height=4,results=hide>>=
set.seed(123)
X <- simulate(mod1)
plot(X)
@

\noindent
The \code{simulate} function fills in addition the two slots \code{data} and \code{sampling} of the \code{yuima} object. 
<<>>=
str(X,vec.len=2)
@
More details on how to change the default sampling scheme for the \code{simulate} method and how to perform subsampling will be given in Section \ref{sec:simul}.


\subsection{User Specified State and Time Variables}
Suppose now that the user wants to specify her own model using a prescribed notation, e.g., some sdes like
$$\de Y_s = -3 s Y_s \de s + \frac{1}{1+Y_s^2}\de W_s,$$
where $a(s,y) = -3sy$ and $b(y) = 1/(1+y^2)$.
Then this model can be described in \pkg{yuima} as follows
<<echo=TRUE, print=FALSE,results=hide>>=
mod1b <- setModel(drift = "-3*s*y", diffusion = "1/(1+y^2)", 
state.var="y", time.var="s")
@
In this case the solution variable is the same as the state variable. Indeed, the \code{yuima.model} object appears as follows
<<>>=
str(mod1b)
@
Once again, the user may use the \code{simulate} method to perform simulation.

\subsection{Specification of Parametric Models}\label{sec:par}
Assume now that we want to specify a parametric model like this
$$\de X_t = -\theta X_t \de t + \frac{1}{1+X_t^\gamma}\de W_t$$
where $a(x,\theta) = -\theta x$ and $b(x,\gamma) = 1/(1+x^\gamma)$.
Then, \pkg{yuima} attempts to distinguish the parameters' names from the ones of the state and time variables
<<echo=TRUE, print=FALSE,results=hide>>=
mod2 <- setModel(drift = "-theta*x", diffusion = "1/(1+x^gamma)")
@
so, in this case, \code{theta} and \code{gamma}, which are different form \code{x} and \code{t}, are assumed to be parameters. Notice that in the above notation $\theta$ and $\gamma$ are generic names for the components of a parameters' vector $\theta$ in the notation of Section \ref{sec:model}.
<<>>=
str(mod2)
@
In order to simulate the parametric model it is necessary to specify the values of the parameters $\theta$ and $\gamma$ as shown in the next code chunk
<<echo=TRUE, print=FALSE,fig=TRUE,height=4,results=hide>>=
set.seed(123)
X <- simulate(mod2,true.param=list(theta=1,gamma=3))
plot(X)
@

\subsection{Multidimensional Processes}\label{sec:multi}
Next is an example of a system of two stochastic differential equations for the couple $(X_{1,t}, X_{2,t})$ driven by three independent Brownian motions $(W_{1,t}, W_{2,t}, W_{3,t})$
$$
\begin{aligned}
\de X_{1,t} &= -3 X_{1,t} \de t + \de W_{1,t} + X_{2,t} \de W_{3,t}\\
\de X_{2,t} &= -(X_{1,t} + 2 X_{2,t}) \de t + X_{1,t} \de W_{1,t} + 3 \de W_{2,t}
\end{aligned}
$$
but this has to be organized into matrix form with a vector of drift expressions and a diffusion matrix
$$
\left(\begin{array}{c}\de X_{1,t} \\\de X_{2,t}\end{array}\right)=
\left(\begin{array}{c} -3 X_{1,t} \\  -X_{1,t} - 2X_{2,t}\end{array}\right)\de t +
\left(\begin{array}{ccc}1 & 0 & X_{2,t} \\X_{1,t} & 3 & 0\end{array}\right)
\left(\begin{array}{c}\de W_{1,t} \\ \de W_{2,t} \\ \de W_{3,t}\end{array}\right)
$$
For this system it now necessary to instruct \pkg{yuima} about the state variable on bot the left-hand side of the equation and the right-hand side of the equation, i.e. the \code{solve.variable}.
<<echo=TRUE, print=FALSE,results=hide>>=
sol <- c("x1","x2") # variable for numerical solution
a <- c("-3*x1","-x1-2*x2")   # drift vector 
b <- matrix(c("1","x1","0","3","x2","0"),2,3)  #  diffusion matrix
mod3 <- setModel(drift = a, diffusion = b, solve.variable = sol)
@
Looking at the structure of the \code{noise.number} slot in \code{mod3}, one can see that this is now set to 3 which is taken as the number of columns of the diffusion matrix.
Again, this model can be easily simulated
<<echo=TRUE, print=FALSE,fig=TRUE,width=9,height=4,results=hide>>=
set.seed(123)
X <- simulate(mod3)
plot(X, plot.type="single",lty=1:2)
@

\noindent
But it is also possible to specify more complex models like the following
 \begin{equation} \label{sabr}
 \begin{cases}
 & \mbox{d} X_{1,t} = X_{2,t} \left| X_{1,t} \right|^{2/3} \mbox{d}W_{1,t}, \\
 & \mbox{d}X_{2,t} = g(t)\mbox{d}X_{3,t}, \\
 & \mbox{d}X_{3,t} = X_{3,t}( \mu  \mbox{d}t + \sigma (\rho \mbox{d}W_{1,t} + \sqrt{1-\rho^2}
   \mbox{d}W_{2,t}))
 \end{cases}
 \end{equation}
$$ (X_{1,0}, X_{2,0}, X_{3,0}) = (1.0,0.1,1.0)$$
 with $\mu = 0.1, \sigma = 0.2, \rho = -0.7 $ and $g(t) = 0.4 + (0.1 + 0.2t) e^{-2t}$,  for
 example, where $W = (W_1, W_2)$ is a 2-dimensional standard Brownian motion. In order to pass this model to \pkg{yuima} we need to rewrite it in matrix form.
 The solution  $X = (X_1, X_2, X_3)$ takes values on $\mathbb{R}_+^3$.
 This is a stochastic integral equation defined as
 \begin{equation}
 X_t = X_0 +  \int_0^t a(s,X_s) \mbox{d}s + \int_0^t b(s,X_s) \mbox{d}W_s
 \end{equation}
 with 
 \[
  a(s,x) = \left( \begin{array}{@{\,}c@{\,}} 0 \\ g(s) \mu x_3 \\ \mu x_3 \end{array} \right),
 \ \ 
 b(s,x) = \left( \begin{array}{@{\,}cc@{\,}} x_2 | x_1|^{2/3} &  0 \\
  g(s)\sigma \rho x_3 &  g(s)\sigma \sqrt{1-\rho^2} x_3 \\ 
 \sigma \rho  x_3 & \sigma \sqrt{1-\rho^2} x_3 
 \end{array} \right)
 \]
 for $ x = (x_1, x_2, x_3)$. 
<<echo=TRUE, print=FALSE,results=hide>>=
mu <- 0.1
sig <- 0.2
rho <- -0.7

g <- function(t) {0.4 + (0.1 + 0.2*t)* exp(-2*t)}


f1 <- function(t, x1, x2, x3) {
    ret <- 0
    if(x1 > 0 && x2 > 0) ret <- x2*exp(log(x1)*2/3)
    return(ret)
}

f2 <- function(t, x1, x2, x3) {
     ret <- 0
     if(x3 > 0) ret <- rho*sig*x3
     return(ret)
}

f3 <- function(t, x1, x2, x3) {
     ret <- 0
     if(x3 > 0) ret <- sqrt(1-rho^2)*sig*x3
     return(ret)
}

diff.coef.matrix <- matrix(c("f1(t,x1,x2,x3)",
 "f2(t,x1,x2,x3) * g(t)", "f2(t,x1,x2,x3)", "0", 
     "f3(t,x1,x2,x3)*g(t)", "f3(t,x1,x2,x3)"),  3, 2)

sabr.mod <- setModel(drift = c("0", "mu*g(t)*x3", "mu*x3"), 
diffusion = diff.coef.matrix, state.variable = c("x1", "x2", "x3"),
    solve.variable = c("x1", "x2", "x3"))
str(sabr.mod@parameter)
@
The functions \code{f1}, \code{f2} and \code{f3} are defined in a way that, when the trajectory of the processes crosso zero from above, the trajectory is stopped ad zero. Notice that in this way the only visible parameter for \pkg{yuima} is \code{mu} as \code{rho} and \code{sig} are inside the bodies of the functions \code{f2} and \code{f3}. If we want to instruct \pkg{yuima} about these parameters, they should appear explicitly as arguments of the functions as explained by this \proglang{R} code
<<echo=TRUE, print=FALSE,results=hide>>=
 f2 <- function(t, x1, x2, x3, rho, sig) {
     ret <- 0
     if(x3 > 0) ret <- rho*sig*x3
     return(ret)
 }

 f3 <- function(t, x1, x2, x3, rho, sig) {
     ret <- 0
     if(x3 > 0) ret <- sqrt(1-rho^2)*sig*x3
     return(ret)
 }

 diff.coef.matrix <- matrix(c("f1(t,x1,x2,x3)", 
 "f2(t,x1,x2,x3,rho, sig) * g(t)", "f2(t,x1,x2,x3,rho,sig)", 
 "0", "f3(t,x1,x2,x3,rho,sig)*g(t)", "f3(t,x1,x2,x3,rho,sig)"),  3, 2)

 sabr.mod <- setModel(drift = c("0", "mu*g(t)*x3", "mu*x3"), 
 diffusion = diff.coef.matrix, state.variable = c("x1", "x2", "x3"), 
 solve.variable = c("x1", "x2", "x3"))
str(sabr.mod@parameter)
@


\subsection{Fractional Gaussian Noise}\label{sec:fgn}
The \pkg{yuima} allows for the description of stochastic differential equations driven by fractional Brownian motion of the following type
$$\de X_t =  a(X_t) \de t + b(X_t) \de W_t^H
$$
where $W^H=\left( W^H_t, t\geq 0 \right)$ is a normalized fractional Brownian motion (fBM), {\it i.e.} the zero mean Gaussian processes with covariance function
$$\dE( W_s^H W_t^H )= \frac{1}{2} \left[ |s|^{2H}+|t|^{2H}- |t-s|^{2H}\right]$$ with Hurst exponent $H\in(0,1)$.  The fractional Brownian motion process is  neither Markovian nor a semimartingale for $H\neq\frac{1}{2}$ but
remains Gaussian.  For $H > \frac12$, the solution $X_t$ above  presents the long-range dependance property that makes it useful for different applications in biology, physics, ethernet traffic or finance.
In order to specify a stochastic differential equation driven by fractional Gaussian noise it is necessary to specify the value of the Hurst parameter. For example, if we want to specify the following model
$$\de Y_t =  3 Y_t \de t + \de W_t^H$$
we proceed as follows
<<echo=TRUE, print=FALSE,fig=TRUE,width=9,height=6,results=hide>>=
mod4A <- setModel(drift="3*y", diffusion=1, hurst=0.3, solve.var="y")
mod4B <- setModel(drift="3*y", diffusion=1, hurst=0.7, solve.var="y")
set.seed(123)
X1 <- simulate(mod4A,sampling=setSampling(n=1000))
X2 <- simulate(mod4B,sampling=setSampling(n=1000))
par(mfrow=c(2,1))
par(mar=c(2,3,1,1))
plot(X1,main="H=0.3")
plot(X2,main="H=0.7")
@

\noindent
In this case, the appropriate slot is now filled
@ 
<<>>=
str(mod4A)
@
The user can choose between  two simulation schemes, namely the Cholesky method and \citet{WoodChan} method. This is done via the argument \code{methodfGn} in the \code{simulate} method. The default simulation scheme is Wood and Chan and it is chosen by setting \code{methodfGn="WoodChan"}, the other simply by setting \code{methodfGn} to \code{Cholesky}.

\subsection{L\'evy Processes}\label{sec:jump}
Jump processes can be specified in different ways in mathematics and hence in \pkg{yuima} package. 
Let $Z_t$ be a  Compound Poisson Process (i.e., jumps size follow some distribution, like the Gaussian law and jumps occur at Poisson times).
Then it is possible to consider the following SDE which involves jumps
$$\de X_t =  a(X_t)\de t + b(X_t)\de W_t + \de Z_t$$
In the next example we consider a compound Poisson process with intensity $\lambda=10$ with Gaussian jumps.
This model can be specified in \code{setModel} using the argument  \code{measure.type="CP"} 
A simple Ornstein-Uhlenbeck process with Gaussian jumps 
$$\de X_t = -\theta X_t \de t + \sigma \de W_t + \de Z_t$$
is specified as
<<echo=TRUE, print=FALSE,fig=TRUE,width=9,height=4,results=hide>>=
mod5 <- setModel(drift=c("-theta*x"), diffusion="sigma",
 jump.coeff="1", measure=list(intensity="10", df=list("dnorm(z, 0, 1)")),
 measure.type="CP", solve.variable="x")
set.seed(123)
X <- simulate(mod5, true.p=list(theta=1,sigma=3),sampling=setSampling(n=1000))
plot(X)
@

\noindent
Another possibility is to specify the jump component via the L\'evy measure. Without going into too much details, here is an example of specification of a simple Ornstein-Uhlenbeck  process with IG (Inverse Gaussian) L\'evy measure 
$$\de X_t = -x \de t + \de Z_t$$
<<echo=TRUE, print=FALSE,fig=TRUE,width=9,height=4,results=hide>>=
mod6 <- setModel(drift="-x", xinit=1, jump.coeff="1", 
  measure.type="code", measure=list(df="rIG(z, 1, 0.1)"))
set.seed(123)
X <- simulate(mod6, sampling=setSampling(Terminal=10, n=10000)) 
plot(X)
@

\subsection{Specification of Generic Models}
In general, the \pkg{yuima} package allows to specify a large family of models solutions to
$$\de X_t =a(X_t)\de t +  b(X_t)\de W_t + c(X_t)\de Z_t$$
using the following interface
<<echo=TRUE, print=FALSE,eval=FALSE>>=
setModel(drift, diffusion, hurst = 0.5, jump.coeff,
 measure, measure.type, state.variable = "x",
 jump.variable = "z", time.variable = "t", solve.variable, xinit)
@
The \pkg{yuima} package implements many multivariate Random Numbers Generators (RNG) which are needed to simulate L\'evy paths including
\code{rIG} (Inverse Gaussian), \code{rNIG} (Normal Inverse Gaussian), \code{rbgamma} (Bilateral Gamma), \code{rngamma} (Normal Gamma) and \texttt{rstable} (Stable Laws).
Other user-defined RNG can be used freely.

\section{Simulation, Sampling and Subsampling}\label{sec:simul}
The \code{simulate} function simulates \code{yuima} models according to Euler-Maruyama scheme in the presence of non-fractional diffusion noise and L\'evy jumps and uses the Cholesky or the Wood and Chan methods for the fractional Gaussian noise.
The \code{simulate} function accepts several arguments including the description of the sampling structure, which is an object of type \code{yuima.sampling}. The \code{setSampling} allows for the specification of different sampling parameters including random sampling. Further, the \code{subsampling} allows us to subsample a trajectory of a simulated stochastic differential equation or a given time series in the \code{yuima.data} slot of a \code{yuima} object.
Sampling and subsampling can be specified jointly as arguments to the \code{simulate} function. This is convenient if one wants to simulate data at very high frequency but then return only low frequency data for inference or other applications. In what follows we explain how to specify  arguments of these \pkg{yuima} functions.   Complete details can be found in  the man pages of the \pkg{yuima} package.

Assume that we want to simulate this model
$$
\begin{aligned}
\de X_{1,t} &= -\theta X_{1,t} \de t + \de W_{1,t} + X_{2,t} \de W_{3,t}\\
\de X_{2,t} &= -(X_{1,t} + \gamma X_{2,t}) \de t + X_{1,t} \de W_{1,t} + \delta \de W_{2,t}
\end{aligned}
$$
Now we prepare the model using the \code{setModel} constructor function
<<setModel1>>=
sol <- c("x1","x2") # variable for numerical solution
b <- c("-theta*x1","-x1-gamma*x2")   # drift vector 
s <- matrix(c("1","x1","0","delta","x2","0"),2,3)  #  diffusion matrix
mymod <- setModel(drift = b, diffusion = s, solve.variable = sol)
@
Suppose now that we want to simulate the process on a regular grid on the interval $[0,3]$ and $n=3000$ observations. We can prepare the sampling structure as follows
<<>>=
samp <- setSampling(Terminal=3, n=3000)
@
and look inside it
<<>>=
str(samp)
@
As seen from the output, the sampling structure is quite rich and we will show how to specify some of the slots later on.
We now simulate this process specifying the \code{sampling} argument to \code{simulate}
<<>>=
set.seed(123)
X2 <- simulate(mymod, sampling=samp)
@
now the sampling structure is recorded along with the data in the \code{yuima} object \code{X2}
<<>>=
str(X2@sampling)
@
\subsubsection{Subsampling}
The sampling structure can be used to operate subsampling. Next example shows how to perform Poisson random sampling, with two independent Poisson processes, one per coordinate of \code{X2}.
<<sub1>>=
newsamp <- setSampling(
random=list(rdist=c( function(x) rexp(x, rate=10), 
function(x) rexp(x, rate=20))) )
str(newsamp)
@
In the above we have specified two independent exponential  distributions to represent Poisson arrival times. Notice that the slot \code{regular} is now set to \code{FALSE}.
Now we subsample the original trajectory of \code{X2} using the \code{subsampling} function
<<sub2,fig=TRUE,width=9,height=5>>=
newdata <- subsampling(X2, sampling=newsamp)
plot(X2,plot.type="single", lty=c(1,3),ylab="X2")
points(get.zoo.data(newdata)[[1]],col="red")
points(get.zoo.data(newdata)[[2]],col="green",pch=18)
@

Or we can operate a deterministic sampling specifying two different regular frequencies
<<sub3,fig=TRUE,width=9,height=5>>=
newsamp <- setSampling(delta=c(0.1,0.2))
newdata <- subsampling(X2, sampling=newsamp)
plot(X2,plot.type="single", lty=c(1,3),ylab="X2")
points(get.zoo.data(newdata)[[1]],col="red")
points(get.zoo.data(newdata)[[2]],col="green", pch=18)
@

Again one can look at the structure of the sampling structure.

Subsampling can be used within the \code{simulate} function. What is usually done in simulation studies, is to simulate the process at very high frequency but then use data for estimation at a lower frequency.
This can be done in a single step in the following way.
<<sub4,fig=TRUE,width=9,height=5>>=
set.seed(123)
Y.sub <- simulate(mymod,sampling=setSampling(delta=0.001,n=1000),
subsampling=setSampling(delta=0.01,n=100))
set.seed(123)
Y <- simulate(mymod, sampling=setSampling(delta=0.001,n=1000))
plot(Y, plot.type="single")
points(get.zoo.data(Y.sub)[[1]],col="red")
points(get.zoo.data(Y.sub)[[2]],col="green",pch=18)
@

In the previous code we have simulated the process twice just to show the effect of the subsampling but the reader should use only the line which outputs the simulation to \code{Y.sub} as seen in the next plot.
<<sub5,fig=TRUE,width=9,height=5>>=
plot(Y.sub, plot.type="single")
@



\section{Asymptotic Expansion}\label{sec4}
For numerical computation of the expectation of a random variable,
the Monte-Carlo method gives a universal solution although it is time consuming and involves 
 stochastic errors of certain scale 
depending on the number of repetitions. 
An alternative method is the asymptotic expansion, that can often give a solution with accuracy comparable or superior to  
Monte-Carlo approaches, 
besides, it has advantage in the computation time because of the approximation by an analytic formula. 


%The \pkg{yuima} 
%package  provides numerical approximation to the expectation of 
%a functional of a diffusion process in terms of the asymptotic expansion scheme.
Let us consider a family of 
 $d$-dimensional diffusion processes  $X=(X^{(\ve)}_t)_{t\in[0,T]}$ ($\ve\in(0,1]$) specified 
 by the stochastic integral equation
\begin{equation}\label{asy01}
X_t^{(\ve)} = x_0+\int_0^t a(X_s^{(\ve)},\ve)\de s + \int_0^t b(X_s^{(\ve)},\ve)\de W_s, \qquad t\in[0,T]
\end{equation}
 for $\ve \in(0,1]$, 
where  $W_t=(W_{1,t}, \ldots, W_{r,t})$ is an $r$-dimensional Wiener process.
The functional of interest is expressed in the following abstract form
\begin{equation}
\label{yuima:func1}
F^{(\ve)}  = \sum_{\alpha=0}^r \int_0^T f_\alpha(X_t^{(\ve)},\ve)\de W_t^\alpha + F(X_T^{(\ve)},\ve), \qquad W_t^0=t.
\end{equation} 

A typical application is the Asian option pricing. For example, in the Black-Scholes model
\begin{equation}
\label{eqyuima:gbm1}
\de X_t^{(\ve)} = \mu X_t^{(\ve)}\de t + \ve X_t^{(\ve)} \de W_t, 
\end{equation}
the price of the option under zero interest rate is of the form
$$ \dE\left[\max\left( \frac{1}{T}\int_0^T X_t^{(\ve)} \de t - K,0\right)\right].$$
%
Thus the functional of interest is
$$F^{(\ve)} = \frac{1}{T}\int_0^T X_t^{(\ve)} \de t, \qquad r=1$$ 
with
$$
f_0(x,\ve) = \frac{x}{T}, \quad f_1(x,\ve)=0, \quad  F(x, \ve) = 0
$$
in \eqref{yuima:func1}.
%
%\begin{en-text}%%%%%%%%%%%
%So, the call option price requires the composition  of a smooth functional
%$$F^\ve(X_t^{(\ve)}) = \frac{1}{T}\int_0^T X_t^{(\ve)} \de t, \qquad r=1$$
%with the irregular function
%$$
%\max(x-K,0)
%$$
%\end{en-text}%%%%%%%%%%
%
 Similarly, for $F(x,\ve)=x$, 
the functional becomes $F^{(\ve)}=X^{(\ve)}_T$ and the price of the European call option is 
$\dE[\max(X^{(\ve)}_T-K,0)]$. This value has a closed form in the Black-Sholes economy but 
it is necessary to apply some numerical method for pricing the Asian option even in this linear case.

Returning to the general system (\ref{asy01})-(\ref{yuima:func1}), 
we will assume that the stochastic system is deterministic in the limit as $\ep\downarrow0$, 
that is,  
\beas
b(\cdot,0)\>=\>0 \sskip\mbox{and}\sskip f_\alpha(\cdot,0)=0\sskip(\alpha=1,...,r).
\eeas
%
Since $X^{(0)}_t$ is deterministic solution to the ordinary differential equation 
\beas 
\de X^{(0)}_t/\de t =a(X^{(0)}_t,0),&& X^{(0)}_0=x_0,
\eeas
the functional $F^{(0)}$ becomes a constant given by 
\bea\label{130106-1}
F^{(0)} &=& \int_0^T f_0(X^{(0)}_t,0)\de t+F(X^{(0)}_T,0).
\eea

Under standard regularity of $a$, $b$, $f_\alpha$ and $F$, 
it is possible to show $F^{(\ep)}$ has a version that is smooth in $\ep\in[0,1)$ almost surely, and hence, 
\beas 
\tilde{F}^{(\ep)} &:=& \ep^{-1}(F^{(\ep)}-F^{(0)})
\eeas
admits a stochastic expansion 
\bea\label{130206-8} 
\tilde{F}^{(\ep)} &\sim& 
\tilde{F}^{[0]}+\ep\tilde{F}^{[1]}+\ep^2\tilde{F}^{[2]}+\cdots
\eea
as $\ep\downarrow0$. 
This stochastic expansion makes sense in the Sobolev spaces of the Malliavin calculus. 
Then the so-called Watanabe's theory (\cite{Watanabe87}) validates 
the asymptotic expansion of the (generalized) expectation 
\bea\label{130206-2}
\dE[g(\tilde{F}^{(\ep)})] &\sim& d_0(g)
+\ep d_1(g)+\ep^2 d_2(g)+\cdots
\eea
as $\ep\downarrow0$ for measurable functions $g$ at most polynomial growth or 
more generally for Schwartz distributions, 
under the uniform nondegeneracy of the Malliavain covariance of $\tilde{F}^{(\ep)}$.
\footnote{This condition ensures smoothness of the distribution of $\tilde{F}^{(\ep)}$. 
It should be remarked that the Watanabe's theory is more general than the present use 
for the variable $\tilde{F}^{(\ep)}$ having a Gaussian principal part $\tilde{F}^{(0)}$. }
%
In the present situation, each $d_i(g)$ is expresses as 
\beas 
d_i(g) &=& \int g(z)p_i(z)\phi(z;0,v)dz,
\eeas
where $p_i$ is a polynomial and $\phi(z;0,v)$ is the density of the normal distribution $N(0,v)$ 
with $v=\mbox{Cov}[\tilde{F}^{(0)}]$. 
Polynomials $p_i$ are given by the conditional expectation of multiple Wiener integrals. 
%This expansion formula is implemented in \pkg{yuima}. 
%In finance, we can apply this expansion to $g(z)=\max(z-c,0)$, for example. 
The expansion (\ref{130206-2}) holds uniformly in a class of functions $g$. 






As mentioned above, 
Monte Carlo methods require a huge number of simulations to get the desired accuracy of the
calculation of the expectation, while the asymptotic expansion of $F^{(\ve)}$ gives very fast 
and accurate approximation by analytic formulation.
The \pkg{yuima}  package provides functions to construct the functional $F^{(\ve)}$, and automatic asymptotic expansion based on the Malliavin calculus.  starting from a  \pkg{yuima} object. 
This asymptotic expansion approach to option pricing was proposed in early 1990's 
( \citep{Yoshida92b}, \citep{Takahashi99}, \citep{Kunitomo01}), and 
many related papers are available today. 


Though our method can be applied to the nonlinear system (\ref{asy01})-(\ref{yuima:func1}), 
just for an example, we shall consider 
the Asian call option of the geometric Brownian motion of equation \eqref{eqyuima:gbm1} with $\mu=1$ and $x_0=1$, 
and 
\bea\label{130206-5} 
g(x)&=& %F^{(0)}-K+\ep x\>=\>\ep\left(
\max\left(F^{(0)}-K+\ep x,0\right)%\right). 
\eea
Set the model  (\ref{asy01}) and the functional (\ref{yuima:func1}) as follows:
<<echo=TRUE, print=FALSE, results=hide>>=
model <- setModel(drift = "x", diffusion = matrix( "x*e", 1,1))
T <- 1
xinit <- 150
K <- 100
f <- list( expression(x/T), expression(0))
F <- 0
e <- 0.5
yuima <- setYuima(model = model, sampling = setSampling(Terminal=T, n=1000))
yuima <- setFunctional( yuima, f=f,F=F, xinit=xinit,e=e)
@
This time the \code{setFunctional} command fills the appropriate slots inside the \code{yuima} object
<<echo=TRUE, print=FALSE>>=
str(yuima@functional)
@
Then the limit $F^{(0)}$ of $F^{(\ep)}$ is easily obtained by calling the function \code{F0} on the \code{yuima} object:
<<echo=TRUE, print=FALSE>>=
F0 <- F0(yuima)
F0
@
Set the function $g$ according to (\ref{130206-5}): 
%<<>>=
%max(F0-K,0)  # asian call option price
%@
%We can go up to the first order approximation adding one term to the expansion
<<echo=TRUE, print=FALSE,results=hide>>=
rho <- expression(0)
epsilon <- e  # noise level
g <- function(x) {
  tmp <- (F0 - K) + (epsilon * x) 
 tmp[(epsilon * x) < (K-F0)] <- 0
 tmp
}
@
Now we are at the point of computing the coefficients $d_i$ ($i=0,1,2$) in the expansion of 
the price $\dE[\max(F^{(\ep)}-K,0)]$ 
by applying the function \code{asymptotic_term}: 
<<echo=TRUE, print=FALSE,results=hide>>=
asymp <- asymptotic_term(yuima, block=10, rho, g)
asymp
@
Then the sums 
<<echo=TRUE, print=FALSE>>=
asy1 <- asymp$d0 + e * asymp$d1  # 1st order asymp. exp. of asian call price
asy1
asy2 <- asymp$d0 + e * asymp$d1+ e^2* asymp$d2  # 2nd order asymp. exp. of asian call price
asy2
@
give the first and second order asymptotic expansions, respectively.
 
We remark that the expansion of $\dE[g(\tilde{F}^{(\ep)})G^{(\ep)}]$ is also possible by the same method 
for a functional $G^{(\ep)}$ having a stochastic expansion like (\ref{130206-8}). 
Thus our method works even under the existence of a stochastic discount factor. 


One can compare the result of the asymptotic expansion with other well known techniques like Edgeworth series expansion for the log-normal distribution as proposed, e.g.,  in \citet{Levy92}. This approximation is available through the package \pkg{fExoticOptions}.
%%% https://www.rocq.inria.fr/mathfi/Premia/free-version/doc/premia-doc/pdf_html/asian_doc/index.html#x1-80005.1.1
<<>>=
library(fExoticOptions)
levy <- LevyAsianApproxOption(TypeFlag = "c", S = xinit, SA = xinit, X = K, 
      Time = 1, time = 1, r = 0.0, b = 1, sigma = e)@price
levy
@
and the relative difference between the two approximations is \Sexpr{round((asy2-levy)/asy2*100,1)}\%.

\subsubsection{Asymptotic Expansion for General Stochastic Processes}
Of course, \pkg{yuima} approach is more general in that the above Levy approximation only holds when the process $X_t$ is the geometric Brownian motion. We now give an example when the underlying process $X_t$ is the following CIR model
$$
\de X_t =  0.9 X_t \de t + \ep \sqrt{X_t} \de W_t, X0 = 1
$$
and we calculate the asymptotic expansion of a european call option with strike price $K=10$ for $\ep=0.4$.

<<>>=
a <- 0.9
e <- 0.4
Terminal <- 3

xinit <- 1
K <- 10

drift <- "a * x"
diffusion <- "e * sqrt(x)"

model <- setModel(drift=drift,diffusion=diffusion)

n <- 1000*Terminal
yuima <- setYuima(model = model,sampling = setSampling(Terminal=Terminal,n=n))

f <- list(c(expression(0)),c(expression(0)))
F <- expression(x)

yuima.ae <- setFunctional(yuima,f=f,F=F,xinit=xinit,e=e)
rho <- expression(0)
F1 <- F0(yuima.ae)


get_ge <- function(x,epsilon,K,F0){
	tmp <- (F0 - K) + (epsilon * x[1])
	tmp[(epsilon * x[1]) > (K - F0)] <- 0
	return( - tmp )
}


g <- function(x){
	return(get_ge(x,e,K,F1))
}

time1 <- proc.time()
asymp <- asymptotic_term(yuima.ae,block=100,rho,g)
time2 <- proc.time()
@
We now extract the first and second order terms of the asymptotic expansion from the \code{asymp} object
<<>>=
ae.value0 <- asymp$d0
ae.value0
ae.value1 <- asymp$d0 + e * asymp$d1
ae.value1
ae.value2 <- as.numeric(asymp$d0 + e * asymp$d1 + e^2 * asymp$d2)
ae.value2
ae.time <- time2 - time1
ae.time
@
As it can be seen, the contribution of the term corresponding to the second order of the asymptotic expansion give a real contribution to the approximation and the final approximated value \Sexpr{round(ae.value2,5)} can be compared with a Monte Carlo estimate based on 1000000 replications 
which is equal to \code{0.561059}, but more demanding in terms of cpu time. The relative difference among the two estimates is \Sexpr{round((ae.value2-0.561059)/0.561059*100,1)}\%.

\section{Inference for Stochastic Processes}\label{sec5}
The \pkg{yuima} implements several optimal techniques for parametric, semi- and non-parametric estimation of (multidimensional) stochastic differential equations. Most of the techniques presented below apply to high frequency data, i.e. when $\Delta_n$, the time lag between to consecutive observations of the process, converges to zero as  the number  $n$ of observations       increases.

\subsection{How to Input Data Into a \code{yuima} Object}
Although most of the examples in this section are given on simulated data, the main way to fill up the \code{data} slot of a \code{yuima} object is to use the function \code{setYuima}. The function \code{setYuima} sets various slots of the \code{yuima} object. In particular, to estimate a \code{yuima.model} called \code{mod} on the data \code{X} one can use a code like this \code{my.yuima <- setYuima(data=setData(X), model=mod)} and then pass \code{my.yuima} to the inference functions as described in what follows.


For example, assuming that an Internet connection is available, the following simple list of commands downloads data from the internet and constructs a \code{yuima} object with the \code{data} slot containing the time series.
<<echo=TRUE, print=FALSE,results=hide,tidy=TRUE>>=
data <- read.csv("http://chart.yahoo.com/table.csv?s=IBM&g=d&x=.csv")
x <- setYuima(data=setData(data$Close))
str(x@data)
@

\subsection{Quasi Maximum Likelihood Estimation}\label{section-qmle}
Consider a multidimensional diffusion process
\begin{equation}
\label{eq:sdemle}
\de X_t = a(X_t,\theta_2)\de t + b(X_t,\theta_1) \de W_t,\quad X_0=x_0,
\end{equation}
where $W_t$ is an {$r$}-dimensional standard Wiener process 
independent of the initial variable $X_0$. 
Moreover, $\theta_1\in\Theta_1\subset \mathbb{R}^p$, 
$\theta_2\in\Theta_2\subset \mathbb{R}^q$,
$a:\mathbb{R}^d\times\Theta_2 \to \mathbb{R}^d$ and $b:\mathbb{R}^d\times\Theta_1 \to \mathbb{R}^d\times \mathbb{R}^r$. 
The naming of $\theta_2$ and $\theta_1$ is theoretically natural in view of the optimal convergence rates of the estimators for these parameters.
Given sampled data ${\bf X}_n = (X_{t_i})_{i=0,\ldots,n}$ with $t_i = i\Delta_n$,
QMLE (Quasi Maximum Likelihood Estimator) makes use of the following approximation of the true log-likelihood for multidimensional diffusions
{\small
\begin{eqnarray}\label{qlik}
\ell_n({\bf X}_n,\theta)
=-\frac12\sum_{i=1}^n\left\{\log\text{det}(\Sigma_{i-1}(\theta_1))
+\frac{1}{\Delta_n}
\Sigma_{i-1}^{-1}(\theta_1)[(\Delta X_i-\Delta_n a_{i-1}(\theta_2))^{\otimes 2}]\right\}
\end{eqnarray}}
\noindent
where $\theta=(\theta_1, \theta_2)$, $\Delta X_i=X_{t_i}-X_{t_{i-1}}$, $\Sigma_i(\theta_1)=\Sigma(\theta_1,X_{t_i})$, $a_i(\theta_2)=a(X_{t_i},\theta_2)$, $\Sigma=b^{\otimes 2}$, $A^{\otimes 2}= A A^T$ and $A^{-1}$ the inverse of $A$, $A[B] = \mbox{tr}(A B)$.  
Then 
%\citep[see e.g.,][]{Yoshida92, Kessler97, Yoshida11}, 
the QMLE of $\theta$ is an estimator that satisfies  
$$\hat\theta=\arg\max_\theta \ell_n({\bf X}_n,\theta)$$
exactly or approximately. 

The \pkg{yuima} package implements QMLE via the  \code{qmle} function. The interface and the output of the \code{qmle} function are made as similar as possible to those of the standard \code{mle} function in the \pkg{stats4} package of the basic \proglang{R} system. The main arguments to  \code{qmle} consist of a \code{yuima} object and initial values (\code{start}) for the optimizer. The \code{yuima} object must contain the slots \code{model} and \code{data}. The \code{start} argument must be specified as a named list, where the  names of the  elements of the list  correspond to the names of the parameters as they appear in the \code{yuima} object. Optionally, one can specify named lists of \code{upper}  and \code{lower} bounds
to identify the search region of the optimizer. The standard optimizer is \code{BFGS} when no bounds are specified. If bounds are specified then \code{L-BFGS-B} is used. More optimizers can be added in the  future.

\subsubsection{QMLE in Practice}

As an example, we consider the simple model
\begin{equation}
\de X_t = (2-\theta_2  X_t)  \de t + (1+X_t^2)^{\theta_1}  \de W_t, \quad X_0=1
\label{eq:model1}
\end{equation}
with $\theta_1=0.2$ and $\theta_2=0.3$. Before calling \code{qmle}, we generate sampled data $X_{t_i}$, with $t_i = i \cdot n^{-\frac23}$:
<<echo=TRUE, print=FALSE,results=hide>>=
ymodel <- setModel(drift="(2-theta2*x)", diffusion="(1+x^2)^theta1")
n <- 750
ysamp <- setSampling(Terminal = n^(1/3), n = n)
yuima <- setYuima(model = ymodel, sampling = ysamp)
set.seed(123)
yuima <- simulate(yuima, xinit = 1, 
true.parameter = list(theta1 = 0.2, theta2 = 0.3))
@
Now the \code{yuima} object contains both the \code{model} and \code{data} slots. We set the initial values for the optimizer as $\theta_1=\theta_2=0.5$ and we specify them as a named list called \code{param.init}. We can now use the function \code{qmle} to estimate the parameters $\theta_1$ and $\theta_2$ as follows
<<echo=TRUE, print=FALSE,results=hide>>=
param.init <- list(theta2=0.5,theta1=0.5)
low.par <-  list(theta1=0, theta2=0)
upp.par <-  list(theta1=1, theta2=1)
mle1 <- qmle(yuima, start = param.init,  lower = low.par, upper = upp.par)
@
where \code{upp.par} and \code{low.par} are the upper and lower bounds of the search region used by the optimizer (\code{L-BFGS-B} in this case).
The estimated coefficients are extracted from the output object \code{mle1} as follows
<<echo=TRUE, print=FALSE>>=
summary(mle1)
@
%Notice the interface and the output of the \code{qmle} is quite similar to the ones of the standard \code{mle} function of the \pkg{stats4} package of the base \proglang{R} system.

\subsubsection{Theoretical Remarks on QMLE}%, High-freq \& ergodicity}
Here are some theoretical remarks. 
Consistency must be required when an estimator is applied; otherwise 
the estimation would lose mathematical backing because 
the more data the observer obtains, the worse the estimator behaves. 
For consistency of $\hat{\theta}_1$, we are assuming 
$\Delta_n\to0$ as $n\to\infty$. Indeed, under this condition, $\hat{\theta}_1$ 
has asymptotically (mixed) normality 
\citep{GenonCatalotJacod93, UchidaYoshida12}. 
On the other hand, one needs $T=n\Delta_n\to\infty$ for consistency of 
$\hat{\theta}_2$ because 
the Fisher information for $\theta_2$ is finite for a finite $T$ 
and consistent estimation of $\theta_2$ is theoretically impossible. 
When $T\to\infty$, usually ergodicity is assumed to ensure a law of large numbers and as a result 
we obtain 
consistency of $\hat{\theta}_2$, moreover asymptotic normality. 
We assume the condition $n\Delta_n^p\to0$ for $p=2$ 
while applying the quasi log-likelihood (\ref{qlik}) based on the local Gaussian approximation. 
In practical applications, reduction of the parameter's dimension and relaxing 
the above condition to $n\Delta_n^p\to0$ for $p$ bigger than $2$ are very important. 
Adaptive estimation methods were proposed for $p=3$ and for any $p$ 
in \citep{Yoshida92} and \citep{UchidaYoshida11}, respectively, with the convergence of moments 
by a large deviation argument. 
When $T$ is regarded to be not large, the small sample effect on estimation of $\theta_2$ appears, which 
will be discussed in Section \ref{small.sample}. 
Modules for QMLE and Bayes estimators are going to be available for jump-diffusions. 
See Shimizu and Yoshida \citep{ShimizuYoshida2006} 
and Ogihara and Yoshida \citep{OgiharaYoshida2011}. 



\subsection{Adaptive Bayes Estimation}
Consider again the  diffusion process in \eqref{eq:sdemle}
and the quasi likelihood defined in \eqref{qlik}.


The adaptive Bayes type estimator is defined as follows. 
First we choose an initial arbitrary value $\theta_2^\star\in\Theta_2$ and 
pretend $\theta_1$ is the unknown parameter to 
make the Bayesian type estimator $\tilde{\theta}_1$ as 
\begin{equation} 
\tilde{\theta}_1
=  
\Big[\int_{\Theta_1}\exp\{\ell_n(\mathbf{ x}_n,(\theta_1,\theta_2^\star))\}
\pi_1(\theta_1)d\theta_1 \Big]^{-1} \int_{\Theta_1} \theta_1 \exp \{\ell_n(\mathbf{ x}_n,(\theta_1,\theta_2^\star))
\}\pi_1(\theta_1)d\theta_1
\end{equation}
where 
$\pi_1$ is a prior density on $\Theta_1$. 
According to the asymptotic theory 
under hight-frequent samplings, any function $\pi_1$ can be used
if it is positive on $\Theta_1$. 
For estimation of $\theta_2$, we use $\tilde{\theta}_1$ 
to reform the quasi-likelihood function. That is,
the Bayes type estimator for $\theta_2$ is defined by 
\begin{equation} 
\tilde{\theta}_2
= 
\Big[\int_{\Theta_2}\exp\{ \ell_n(\mathbf{ x}_n,(\tilde{\theta}_1,\theta_2))\}
\pi_2(\theta_2)d\theta_2 \Big]^{-1} \int_{\Theta_2} \theta_2 \exp \{\ell_n(\mathbf{ x}_n,(\tilde{\theta}_1,\theta_2))\}
\pi_2(\theta_2)d\theta_2
\end{equation}
where 
$\pi_2$ is a prior density on $\Theta_2$. 
In this way, we obtain the adaptive Bayes type estimator 
$\tilde{\theta}=(\tilde{\theta}_1,\tilde{\theta}_2)$ 
for $\theta=(\theta_1,\theta_2)$. 

Adaptive Bayes estimation is developed in \pkg{yuima} via the method $\tt adaBayes$.
Consider again the model \eqref{eq:model1} with the same values for the parameters.
In order to perform Bayesian estimation, we prepare prior densities for the parameters.
For simplicity we use uniform distributions in $[0,1]$
<<echo=TRUE>>=
prior <- list(theta2=list(measure.type="code",df="dunif(theta2,0,1)"),
 theta1=list(measure.type="code",df="dunif(theta1,0,1)"))
@
Then we call $\tt adaBayes$, on the same sample data we used for the \code{qmle} function, as follows
<<echo=TRUE, results=hide>>=
bayes1 <- adaBayes(yuima, start=param.init, prior=prior)
@
and we can compare the adaptive Bayes estimates  with the QMLE estimates
<<echo=TRUE>>=
coef(summary(bayes1))
coef(summary(mle1))
@
The argument \code{method="nomcmc"} in \code{adaBayes} performs numerical integration, otherwise MCMC method is used.

The argument \code{method="nomcmc"} in \code{adaBayes} performs numerical integration, otherwise MCMC method is used.

\subsubsection{Theoretical Remarks on Adaptive Bayes Estimator}
Under the same conditions, the adaptive Bayes estimator $\tilde{\theta}_1$ and
$\tilde{\theta}_2$ perform in the same way as $\hat{\theta}_1$ and $\hat{\theta}_2$, respectively. 
See the remark in Section \ref{section-qmle} 
and also \citep{Yoshida92} and \citep{UchidaYoshida12} for details. 




\subsubsection{The Effect of Small Sample Size on Drift Estimation}\label{small.sample}
It is known from the theory that the estimation of the drift in a diffusion process strongly depend on the length of the observation interval $[0,T]$.
In our example above, we took $T=n^\frac13$, with $n = \Sexpr{n}$, which is approximatively   \Sexpr{round(n^(1/3),2)}. Now we reduce the sample size to $n=500$ and then $T=\Sexpr{round(500^(1/3),2)}$.
We then apply both quasi-maximum likelihood and adaptive Bayes type estimators to these data
<<>>=
n <- 500
ysamp <- setSampling(Terminal = n^(1/3), n = n)
yuima <- setYuima(model = ymodel, sampling = ysamp)
set.seed(123)
yuima <- simulate(yuima, xinit = 1, 
true.parameter = list(theta1 = 0.2, theta2 = 0.3))
param.init <- list(theta2=0.5,theta1=0.5)
mle2 <- qmle(yuima, start =param.init , 
lower = list(theta1=0, theta2=0), 
upper = list(theta1=1, theta2=1))
bayes2 <- adaBayes(yuima, start=param.init, prior=prior)
@
and we look at the estimates
<<>>=
coef(summary(bayes2))
coef(summary(mle2))
@
Compared to the results above, we see that the parameters in the diffusion coefficients are estimated with good quality while for the parameters in the drift the quality of estimation deteriorates. The adaptive Bayes estimator seems to perform a little better though.


\subsection{Asynchronous Covariance Estimation}
Suppose that two It\^o processes are observed
only at discrete times in a nonsynchronous manner.
We are interested in estimating the covariance of the two processes accurately
in such a situation.
This type of problem arises typically in high-frequency financial time series.

Let $T \in (0,\infty)$ be a terminal time for possible observations. 
We consider a two dimensional It\^o process $(X_1,X_2)$  
satisfying the stochastic differential equations
\begin{eqnarray*}
\mbox{d}X_{l,t} &=&\mu_{l,t} \mbox{d}t + \sigma_{l,t} \mbox{d}W_{l,t} ,\quad
t\in[0,T]\\
X_{l,0} &=& x_{l,0}        \notag
\end{eqnarray*}
for $l=1,2$. 
Here $W_l$ denote standard Wiener processes with a 
progressively measurable correlation process 
$\mbox{d}\langle W_1 , W_2 \rangle_t = \rho_t \mbox{dt}$,  
$\mu_{l,t}$ and $\sigma_{l,t}$ are progressively measurable processes, 
and $x_{l,0}$ are initial random variables independent of $(W_1,W_2)$.  
Diffusion type processes are in the scope but this model 
can express more sophisticated stochastic structures. 


The process $X_l$ is supposed to be observed at 
over the increasing sequence of times 
$T^{l,i}$ $(i\in\mathbb{Z}_{\geq0})$ starting at $0$, up to time T. 
Thus, the observables are $(T^{l,i},X_{l,i})$ with $T^{l,i}\leq T$. 
Each $T^{l,j}$ may be a stopping time, so possibly depends on 
the history of $(X_1,X_2)$ as well as the precedent stopping times.  
Two sequences of stopping times 
$T^{1,i}$ and $T^{2,j}$ are \textit{nonsynchronous},  and 
irregularly spaced, in general. 
In particular, \code{cce} can apply to estimation of the quadratic variation of a single
stochastic process sampled regularly/irregularly.  


The parameter of interest is the quadratic covariation between $X_1$ and $X_2$: 

\begin{equation}
\theta=
\langle X_1 , X_2 \rangle_T = \int_0^T \sigma_{1,t} \sigma_{2,t} \rho_t \mbox{d}t.
\end{equation}
The target variable $\theta$ is random in general. 

It can be estimated with the nonsynchronous covariance estimator 
(Hayashi-Yoshida estimator) 
\begin{equation}
U_n= \sum_{i,j:T^{1,i}\leq T, T^{2,j}\leq T} (X_{1,T^{1,i}}-X_{1,T^{1,i-1}})(X_{2,T^{2,j}}-X_{2,T^{2,j-1}})
1_{\{ (T^{1,i-1},T^{1,i}] 
\bigcap (T^{2,j-1},T^{2,j}]  \neq \emptyset  \}}.
\end{equation}
That is, the product of any pair of increments $(X_{1,T^{1,i}}-X_{1,T^{1,i-1}})$ and
$(X_{2,T^{2,j}}-X_{2,T^{2,j-1}})$ will make a contribution 
to the sum only when 
the respective observation intervals $(T^{1,i-1},T^{1,i}] $ and $ (T^{2,j-1},T^{2,j}] $ are overlapping 
with each other. 
%The estimator $U_n$ was proposed by Hayashi and Yoshida  and 
It is known that $U_n$ is consist and has asymptotically mixed normal 
distribution 
as $n\to\infty$ if the maximum length between two consecutive observing times 
tends to $0$. 
See \citet{hay-yos05,hay-yos04,hay-yos06,hay-yos08} for details. 

\subsubsection{Example: Data Generation and Estimation by \pkg{yuima} Package}
We will demonstrate how to apply \code{cce} function to
nonsynchronous high-frequency data by simulation. 
As an example, consider a two dimensional stochastic process 
$(X_{1,t},X_{2,t})$ satisfying the stochastic differential equation
\begin{equation}
\begin{split}
\mbox{d}X_{1,t} = \sigma_{1,t} \mbox{d}B_{1,t}, \\
\mbox{d}X_{2,t} = \sigma_{2,t} \mbox{d}B_{2,t}. 
\end{split}
\end{equation}
Here $B_{1,t}$ and $B_{2,t}$ denote two standard Wiener processes, 
however they are correlated as 
\begin{eqnarray}
B_{1,t} &=& W_{1,t},\\
B_{2,t} &=&  \int_0^t \rho_s \mbox{d} W_{1,s} +
  \int_0^t \sqrt{ 1- \rho_s^2} \mbox{d} W_{2,s},
\end{eqnarray}
where  $W_{1,t}$ and $W_{2,t}$ are independent Wiener processes,  and 
$\rho_t$ is the correlation function between $B_{1,t}$ and $B_{2,t}$. 
We consider $\sigma_{l,t},l=1,2$ and $\rho_t$ 
of the following form in this example:
\begin{eqnarray*}
 \sigma_{1,t} &=& \sqrt{1+t}, \\
 \sigma_{2,t} &=& \sqrt{1+t^2}, \\
 \rho_t &=& \frac{1}{\sqrt{2}}.
\end{eqnarray*}
To simulate the stochastic process $(X_{1,t},X_{2,t})$, we first build the model 
by $\tt setModel$ as before. 
It should be noted that the method of generating 
nonsynchronous data can be replaced by a simpler one but 
we will take a general approach here to demonstrate 
a usage of 
the \pkg{yuima} comprehensive package for simulation and estimation of 
stochastic processes. 
<<print=FALSE,echo=TRUE>>=
# diffusion coefficient for process 1
diff.coef.1 <- function(t,x1=0, x2=0) sqrt(1+t)
# diffusion coefficient for process 2
diff.coef.2 <- function(t,x1=0, x2=0) sqrt(1+t^2)
# correlation
cor.rho <- function(t,x1=0, x2=0) sqrt(1/2)
# coefficient matrix for diffusion term
diff.coef.matrix <- matrix( c( "diff.coef.1(t,x1,x2)", 
"diff.coef.2(t,x1,x2) * cor.rho(t,x1,x2)", "", 
"diff.coef.2(t,x1,x2) * sqrt(1-cor.rho(t,x1,x2)^2)"),2,2)
# Model sde using yuima.model
cor.mod <- setModel(drift = c("",""), diffusion = diff.coef.matrix,
 solve.variable=c("x1","x2"))
@ 

The parameter we want to estimate is the quadratic covariation between $X_1$ and $X_2$: 
\begin{equation}
\theta = \langle X_1, X_2 \rangle_T =
 \int_0^T \sigma_{1,t} \sigma_{2,t} \rho_t \mbox{d} t.
\end{equation}
Later, we will compare estimated values with 
the true value of  $\theta$ given by 
<<echo=TRUE>>=
CC.theta <- function( T, sigma1, sigma2, rho)
{
 	tmp <- function(t) return( sigma1(t) * sigma2(t) * rho(t) )
 	integrate(tmp,0,T)
}
@ 
For the sampling scheme, we will consider the independent Poisson sampling. 
That is, each configuration of the sampling times $T^{l,i}$ is realized 
as the Poisson random measure with intensity $np_l$, 
and the two random measures are independent each other as well as 
the stochastic processes. Under this scheme data become asynchronous. It is known that 
\begin{equation}
n^{1/2} ( U_n -\theta) \rightarrow N(0,c),
\end{equation}
as $n\to\infty$, 
where 
\begin{equation}
 c = \left( \frac{2}{p_1} + \frac{2}{p_2} \right)
\int_0^T \left( \sigma_{1,t} \sigma_{2,t}  \right)^2 \mbox{d}t +
\left(
\frac{2}{p_1} + \frac{2}{p_2} - \frac{2}{p_1 + p_2}
\right)
\int_0^T
\left(
\sigma_{1,t} \sigma_{2,t} \rho_t
\right)^2 \mbox{d} t.
\label{eq:vc}
\end{equation}
<<>>=
set.seed(123)
 
Terminal <- 1
n <- 1000
# Cumulative Covariance
theta <- CC.theta(T=Terminal, sigma1=diff.coef.1, 
sigma2=diff.coef.2, rho=cor.rho)$value
cat(sprintf("theta=%5.3f\n",theta))
@
so in our case $\theta=\Sexpr{round(theta,2)}$.
<<results=hide>>=
yuima.samp <- setSampling(Terminal=Terminal,n=n)
yuima <- setYuima(model=cor.mod, sampling=yuima.samp)
X <- simulate(yuima)
@
\code{cce} takes the sample and returns 
an estimate of the quadratic covariation. For example, for the complete data
<<>>=
cce(X)
@
<<cceplot1,fig=TRUE,width=9,height=5>>=
plot(X,main="complete data")
@

We now apply random sampling in the following way: we define a new sampling structure via \code{setSampling} specifying in the argument \code{random} 
a list which contains a vector of random distributions. For the $i$-th component of $X$ we specificy an exponential distribution with rate $n \cdot p_i/T$ for the random times. This will generate Poisson random times with the corresponding rate. 
<<>>=
p1 <- 0.2
p2 <- 0.3
newsamp <- setSampling(
 random=list(rdist=c( function(x) rexp(x, rate=p1*n/Terminal), 
  function(x) rexp(x, rate=p1*n/Terminal))) )
@
Now we use the \code{subsampling} function to subsample the original data \code{X} into new asynchronous data \code{Y}
<<>>=
Y <- subsampling(X, sampling=newsamp)
cce(Y)
@ 
<<cceplot2,fig=TRUE,width=9,height=5>>=
plot(Y,main="asynchronous data")
@

\subsubsection{Asynchronous Estimation for Nonlinear Systems}
Consider now the two-dimensional system with nonlinear feedback
$$
\begin{aligned}
\de X_t &= Y_t\de t + \sigma_1(t,X_t,Y_t) \de W_t\\
\de Y_t &= -X_t\de t + \rho(t,X_t,Y_t)\sigma_2(t,X_t,Y_t) \de W_t+
\sigma_2(t,X_t,Y_t)\sqrt{1-\rho^2(t,X_t,Y_t)}\de B_t
\end{aligned}
$$
with $ \sigma_1(t,X_t,Y_t)=\sqrt{|X_t|(1+t)}$,
$ \sigma_2(t,X_t,Y_t)=\sqrt{|Y_t|}$,
$\rho(t,X_t,Y_t) = \frac{1}{1+X_t^2}$ and $W_t$, $B_t$, two independent
Brownian motions.
We construct the model and we generate data from it
<<>>=
b1 <- function(x,y) y
b2 <- function(x,y) -x
s1 <- function(t,x,y) sqrt(abs(x)*(1+t))
s2 <- function(t,x,y) sqrt(abs(y))
cor.rho <- function(t,x,y) 1/(1+x^2)
diff.mat <- matrix(c("s1(t,x,y)", "s2(t,x,y) * cor.rho(t,x,y)","",
 "s2(t,x,y) * sqrt(1-cor.rho(t,x,y)^2)"), 2, 2) 
cor.mod <- setModel(drift = c("b1","b2"), diffusion = diff.mat,
solve.variable = c("x", "y"),state.var=c("x","y"))

## Generate a path of the process
set.seed(111) 
Terminal <- 1
n <- 10000
yuima.samp <- setSampling(Terminal = Terminal, n = n) 
yuima <- setYuima(model = cor.mod, sampling = yuima.samp) 
yuima <- simulate(yuima, xinit=c(2,3)) 
@
We apply the same Poisson random sampling so that the object \code{Y} will contain  asynchronous data
<<>>=
p1 <- 0.2
p2 <- 0.3
newsamp <- setSampling(
random=list(rdist=c( function(x) rexp(x, rate=p1*n/Terminal), 
function(x) rexp(x, rate=p1*n/Terminal))) )
Y <- subsampling(yuima, sampling = newsamp)
@
<<cceplot3,fig=TRUE,width=9,height=5>>=
plot(Y,main="asynchronous data (non linear case)")
@

The estimated covariance for the complete trajectory \code{yuima}
is now compared with the one obtained on asyncronous data \code{Y}
<<>>=
cce(yuima)
cce(Y)
@

\subsection{Change-Point Analysis}
Consider a multidimensional stochastic differential equation of the form
$$
\de Y_t = a_t \de t + b(X_t,\theta) \de W_t,\ \ t\in[0,T], 
$$
where $W_t$ is an $r$-dimensional Wiener process and $a_t$ and $X_t$ are multidimensional processes, $\theta\in\Theta\subset \mathbb{R}^p$,  $b:\mathbb{R}^d\times\Theta \to \mathbb{R}^d\times \mathbb{R}^r$, is the diffusion coefficient (volatility) matrix.



When $Y=X$ the problem is a diffusion model.
The process $a_t$ may have jumps but should not explode and it is treated as a nuisance in this model.
The change-point problem for the volatility is formalized as follows
$$
Y_t=
\Bigg\{
\begin{array}{ll}
Y_0+\int_0^t a_s \de s+\int_0^t b(X_s,\theta_0^*) \de W_s
& \mbox{ for } t\in[0,\tau^*)
\\
Y_{\tau^*}+\int_{\tau^*}^t a_s \de s+\int_{\tau^*}^t b(X_s,\theta_1^*) \de W_s
& \mbox{ for } t\in[\tau^*,T]. 
\end{array}
$$
The change-point $\tau^*$ instant is unknown and 
is  to be estimated, along with $\theta_0^*$ and $\theta_1^*$, from the observations sampled 
from the path of $(X,Y)$. The \pkg{yuima} implements the quasi-maximum likelihood approach as in \citet{iacyos09} described in the following.
Let  $\Delta_iY=Y_{t_i}-Y_{t_{i-1}}$ and 
define 
\begin{equation} 
\Phi_n(t;\theta_0,\theta_1)
=
\sum_{i=1}^{[nt{/T}]}G_i(\theta_0)+\sum_{i={[nt{/T}]+1}}^nG_i(\theta_1),
\label{eq:phiCH10}
\end{equation}
with 
\begin{equation} 
G_i(\theta) =
\log\det S(X_{t_{i-1}},\theta)
+ \Delta_n^{-1}(\Delta_iY)'S(X_{t_{i-1}},\theta)^{-1}(\Delta_iY)
\label{eq:GiCH10}
\end{equation}
and $S=b^{\otimes 2}$.
Suppose that there exists an estimator 
$\hat{\theta}_k$ for each $\theta_k$, $k=0,1$. 
In case $\theta_k^*$ are known, we define $\hat{\theta}_k$ 
just as $\hat{\theta}_k=\theta_k^*$. 
The change-point estimator  of $\tau^*$ is
\begin{eqnarray*} 
\hat{\tau}&=&\arg\!\!\min\limits_{t\in[0,T]} 
\Phi_n(t;\hat{\theta}_0,\hat{\theta}_1).
\end{eqnarray*}

\subsubsection{Example  of Volatility Change-Point Estimation for 2-Dimensional SDE's}
One example of model that can be analyzed by this technique is, for example, the 2-dimensional stochastic differential equation
$$
\left(\begin{array}{c}
\de X_{1,t}\\ \de X_{2,t} 
\end{array}\right)
= 
\left(\begin{array}{c}
a_1(X_{1,t}) \\
a_2(X_{2,t}) \\
\end{array}\right) \de t
+
\left(\begin{array}{cc}
\theta_{1.k}  \cdot  X_{1,t}&0  \cdot  X_{1,t} \\ 
0  \cdot  X_{2,t}&\theta_{2.k}  \cdot  X_{2,t} \\ 
\end{array}\right)
\left(\begin{array}{c}
\de W_{1,t}\\ \de W_{2,t} 
\end{array}\right),\quad  t\in[0,T],
$$
where $b_1(\cdot)$ and $b_2(\cdot)$ are any functions and $\theta_{1.k}$ and $\theta_{2.k}$ the value of the parameters before ($k=0$) and after $k=1$) the change-point. 
Just for simplicity and in order to simulate some data, we specify some specific form for $b_1(\cdot)$ and $b_2(\cdot)$ but this information will not be used in the change-point analysis.
For example, we will simulate
the following 2-dimensional stochastic differential equation
$$
\left(\begin{array}{c}
 \de X_{1,t}\\ \de X_{2,t} 
 \end{array}\right)
 = 
\left(\begin{array}{c}
 \sin(X_{1,t}) \\
 3 - X_{2,t} \\ 
 \end{array}\right) \de t
 +
\left(\begin{array}{cc}
 \theta_{1.k}  \cdot  X_{1,t}&0  \cdot  X_{1,t} \\ 
 0  \cdot  X_{2,t}&\theta_{2.k}  \cdot  X_{2,t} \\ 
 \end{array}\right)
\left(\begin{array}{c}
 \de W_{1,t}\\ \de W_{2,t} 
 \end{array}\right),\quad  t\in[0,T],
$$
$$
X_{1,0}=1.0,\quad
X_{2,0}=1.0,\quad
$$
with change-point instant at time $\tau=0.4$  and $T=10$.   First, we describe the model to be simulated
<<cpoint1, echo=TRUE,results=hide>>=
diff.matrix <- matrix(c("theta1.k*x1","0*x2","0*x1","theta2.k*x2"), 2, 2)
drift.c <- c("sin(x1)", "3-x2")
drift.matrix <- matrix(drift.c, 2, 1)
ymodel <- setModel(drift=drift.matrix, diffusion=diff.matrix, 
time.variable="t", state.variable=c("x1", "x2"), 
solve.variable=c("x1", "x2"))
@
and then simulate two trajectories. One up to the change-point $\tau=4$ with parameters $\theta_{1.0}=0.5$ and  $\theta_{2.0}=0.3$
<<cpoint3,results=hide>>=
n <- 1000

set.seed(123)

t0 <- list(theta1.k=0.5, theta2.k=0.3)
T <- 10
tau <- 4
pobs <- tau/T
ysamp1 <- setSampling(n=n*pobs, Initial=0, delta=0.01)
yuima1 <- setYuima(model=ymodel, sampling=ysamp1)
yuima1 <- simulate(yuima1, xinit=c(3, 3), true.parameter=t0)

x1 <- yuima1@data@zoo.data[[1]]
x1 <- as.numeric(x1[length(x1)])
x2 <- yuima1@data@zoo.data[[2]]
x2 <- as.numeric(x2[length(x2)])
@
now we generate the second trajectory
 with parameters
$\theta_{1.1}=0.2$ and  $\theta_{2.1}=0.4$. For this trajectory, the initial value is set to the last value of the first trajectory stored in \code{x1} and \code{x2} for the two component of the process.
<<cpoint3b,results=hide>>=
t1 <- list(theta1.k=0.2, theta2.k=0.4)
ysamp2 <- setSampling(Initial=n*pobs*0.01, n=n*(1-pobs), delta=0.01)
yuima2 <- setYuima(model=ymodel, sampling=ysamp2)
yuima2 <- simulate(yuima2, xinit=c(x1, x2), true.parameter=t1)
@
finaly we collate the two trajectories
<<cpoint3c,results=hide>>=
yuima <- yuima1
yuima@data@zoo.data[[1]] <- c(yuima1@data@zoo.data[[1]], 
yuima2@data@zoo.data[[1]][-1])
yuima@data@zoo.data[[2]] <- c(yuima1@data@zoo.data[[2]], 
yuima2@data@zoo.data[[2]][-1])
@ 

The composed trajectory appears as follows
<<cpoint4,fig=TRUE,width=9,height=5>>=
plot(yuima)
@

As said, the change-point analysis do not consider the information coming from the drift part of the model and \pkg{yuima} ignores this internally.
Just to make clear that the information on the drift term is not considered by the function \code{CPoint}, we redefine the \code{yuima} model removing the information coming from the drift and then adding back the data.
<<cpoint4b>>=
noDriftModel <- setModel(drift=c("0", "0"), diffusion=diff.matrix,
 time.variable="t", state.variable=c("x1", "x2"), 
 solve.variable=c("x1", "x2"))
noDriftModel <- setYuima(noDriftModel, data=yuima@data)
noDriftModel@model@drift
@
First we show that there is no difference in using the complete model or the model without drift. For simplicity, we assume the true values of the parameters for $\theta_{1.k}$ and $\theta_{1.k}$
<<cpoint5>>=
t.est <- CPoint(yuima,param1=t0,param2=t1)
t.est$tau
t.est2 <- CPoint(noDriftModel,param1=t0,param2=t1)
t.est2$tau
@
\subsubsection{An Example of Two Stage Estimation}
In practical situations, the initial values of the parameters are not known and there is the need to provide a preliminary estimators of them. One possible approach is the two stage change-point estimation approach as explained in  \citet{iacyos09}. The idea is to take a small subsets of observations at the very beginning and the end of the time series, estimate a
change point and and then refine the estimation.

To this aim, the \pkg{yuima} package contains two  functions
which are useful in the framework of change-point or sequential analysis.
The function \code{qmleL} estimates a model by quasi maximum likelihood using observations in the time interval $[0,t]$ where $t$ can be specificed by the user. In our example, we set \code{t=2}. Similarly for \code{qmleR}, which uses only observations in the time interval $[t, T]$. In our example, we take \code{t=8}.
<<>>=
qmleL(noDriftModel, t=2, start=list(theta1.k=0.1, theta2.k=0.1),
lower=list(theta1.k=0, theta2.k=0), upper=list(theta1.k=1, theta2.k=1), 
method="L-BFGS-B") -> estL
qmleR(noDriftModel, t=8, start=list(theta1.k=0.1, theta2.k=0.1),
lower=list(theta1.k=0, theta2.k=0), upper=list(theta1.k=1, theta2.k=1), 
method="L-BFGS-B") -> estR
t0.est <- coef(estL)
t1.est <- coef(estR)
@
and now we proceed with change-point estimation
<<>>=
t.est3 <- CPoint(noDriftModel,param1=t0.est,param2=t1.est)
t.est3
@
Notice that, even if the estimated parameters are not too accurate because we use a small subsets of observations, the change-point estimate remains good.
We can now refine the estimate of the change point and the parameters but iterating the above procedure.
<<>>=
qmleL(noDriftModel, t=t.est3$tau, start=list(theta1.k=0.1, theta2.k=0.1),
lower=list(theta1.k=0, theta2.k=0), upper=list(theta1.k=1, theta2.k=1), 
method="L-BFGS-B") -> estL
qmleR(noDriftModel, t=t.est3$tau, start=list(theta1.k=0.1, theta2.k=0.1),
lower=list(theta1.k=0, theta2.k=0), upper=list(theta1.k=1, theta2.k=1), 
method="L-BFGS-B") -> estR
t02s.est <- coef(estL)
t12s.est <- coef(estR)
t2s.est3 <- CPoint(noDriftModel,param1=t02s.est,param2=t12s.est)
t2s.est3
@

\subsection{LASSO Model Selection}
The Least Absolute Shrinkage and Selection Operator (LASSO) is a useful and well studied approach to the problem of model selection and its major advantage is the simultaneous execution of both parameter estimation and variable selection (see \citet{Tib96}; \citet{Knight00}; \citet{Efron}). 

To simplify the idea: take a full specified regression model
$$ Y = \theta_0 +  \theta_1 X_1+  \theta_2 X_2 + \cdots +  \theta_k X_k$$
perform least squares estimation under $L_1$ constraints, i.e.

$$\hat\theta = \arg\min_\theta \left\{(Y-\theta X)^T (Y-\theta X) + \sum_{i=1}^k |\theta_i|\right\}$$ 

model selection occurs when some of the $\theta_i$ are estimated as zeros. The same idea can be applied to diffusion processes.
Let $X_t$ be a  diffusion process solution to
$$
\de X_t = a( X_t,\alpha) \de t + b(X_t,\beta)  \de W_t
$$
$$\alpha=(\alpha_1,...,\alpha_{p})'\in\Theta_p\subset \mathbb{R}^p, \quad p\geq1$$
$$\beta=(\beta_1,...,\beta_q)'\in\Theta_q\subset \mathbb{R}^q, \quad q\geq1$$
with $b:\Theta_p\times\mathbb{R}^d\to \mathbb{R}^d$, $\sigma:\Theta_q\times \mathbb{R}^d\to \mathbb{R}^d\times \mathbb{R}^m$ and $W_t,t\in [0,T]$, is a standard Brownian motion in $\mathbb{R}^m$. 
We assume that the functions $a$ and $b$ are known up to   $\alpha$ and $\beta$.
We denote by $\theta=(\alpha,\beta)\in\Theta_p\times \Theta_q=\Theta$ the parametric vector and with $\theta_0=(\alpha_0,\beta_0)$ its unknown true value. 
Let $\mathbb{H}_n({\bf X}_n,\theta) = \ell_n({\bf X}_n,\theta)$ from equation \eqref{qlik}.
The quasi-MLE $\hat{\theta}$ for this model is the solution of the following problem
$$
\hat{\theta}=(\hat\alpha,\hat\beta)'=\arg\min_\theta \mathbb{H}_n({\bf X}_n,\theta)
$$ 
The adaptive LASSO estimator is defined as the solution to the quadratic problem under $L_1$ constraints
$$
\check{\theta}=(\check\alpha,\check\beta)=\arg\min_\theta\mathcal{F}(\theta).
$$
with
$$
\mathcal{F}(\theta)=(\theta-\hat{\theta})^T\ddot{\mathbb{H}}_n({\bf X}_n, \hat\theta)(\theta-\hat{\theta})+\sum_{j=1}^p\lambda_{n,j}|\alpha_j| +\sum_{k=1}^q\gamma_{n,k}|\beta_k|
$$
For more details see \citet{DegIac10b}.
The tuning parameters should be chosen as in \citet{Zou06} in the following way
\begin{equation}
\label{eq:penalty}
\lambda_{n,j} = \lambda_0 |\hat \alpha_{j}|^{-\delta_1}, \qquad
\gamma_{n,k} = \gamma_0 |\hat \beta_{j}|^{-\delta_2}
\end{equation}
where $\hat \alpha_{j}$ and  $\hat \beta_{k}$ are the unpenalized QML estimator of $\alpha_j$ and $\beta_k$ respectively, $\delta_1, \delta_2>0$ and usually taken unitary.

\subsubsection{An Example of Model Selection for Interest Rates Data}
The \code{lasso} method is implemented in the \pkg{yuima} package.
Let us consider the full CKLS model
$$\de X_t = (\alpha+\beta X_t)\de t + \sigma X_t^\gamma\de W_t$$
and let us try to estimate the parameter on  the U.S. Interest Rates monthly data from 06/1964 to 12/1989. We prepare the data, the model and the constraints for optimization
<<results=hide>>=
library(Ecdat)
data(Irates)
rates <- Irates[,"r1"]
plot(rates)
X <- window(rates, start=1964.471, end=1989.333)
mod <- setModel(drift="alpha+beta*x", diffusion=matrix("sigma*x^gamma",1,1))
yuima <- setYuima(data=setData(X), model=mod)
lambda10 <- list(alpha=10, beta =10, sigma =10, gamma =10)
start <- list(alpha=1, beta =-.1, sigma =.1, gamma =1)
low <- list(alpha=-5, beta =-5, sigma =-5, gamma =-5)
upp <- list(alpha=8, beta =8, sigma =8, gamma =8)
@
and now we apply the \code{lasso} function
<<echo=TRUE,results=hide>>=
lasso10 <- lasso(yuima, lambda10, start=start, lower=low, upper=upp,
   method="L-BFGS-B")
@
From which we see that, instead of the general model
$$\de X_t = (\alpha+\beta X_t)\de t + \sigma X_t^\gamma\de W_t$$
<<>>=
round(lasso10$mle, 2)
round(lasso10$lasso, 2)
@
the LASSO method selects the reduced model
$$\de X_t =  0.6 \de t + 0.12 X_t^{\frac32}\de W_t.$$
Notice that this model is not an ergodic one, indicating that the LASSO method shows that the real data are indeed not stationary, but still in the family of CKLS models.

\section{Miscellanea and Roadmap of YUIMA Project}\label{sec6}
Other statistical techniques are already implemented or will be shortly released in the \pkg{yuima}. For example, a nice utility is the function \code{toLatex} for objects of class \code{yuima} and \code{yuima.model}. A simple writing like
\code{toLatex(my-yuima-obj)} produces the related \LaTeX{} code which can be copy and pasted in a mathematical paper.
We also plan to open the the contribution to the YUIMA project to external developers in the near future.



\section*{Acknowledgements}
This work was in part supported by Japan Society for the Promotion of Science Grants-in-Aid for Scientific Research No. 24340015 (Scientific Research), No. 24650148 (Challenging Exploratory Research);
the Global COE program ``The Research and Training Center for New Development in Mathematics'' of the Graduate School of Mathematical Sciences, University of Tokyo;  by a Cooperative Research Program of the Institute of Statistical Mathematics and by the project PRIN 2009JW2STY, Ministero dell'Istruzione dell'Universit\`a e della Ricerca.

Project YUIMA I was in part supported by JST Basic Research Programs PRESTO.
Project YUIMA II is in part supported by NS Solutions Corporation. 
NS Solutions Corporation and The Graduate School of Mathematical Sciences, University of Tokyo are conducting a joint study (Azzurro project) on ``The Application of Advanced Mathematical Statistics Theories in the Financial Industry''. 

 

%\bibliographystyle{natbib} 

\bibliography{bibliography}




\end{document}
